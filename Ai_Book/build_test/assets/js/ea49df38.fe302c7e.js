"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[155],{3497:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>t,metadata:()=>l,toc:()=>c});const l=JSON.parse('{"id":"module-4-vla/chapter-5-cognitive-planning-pipeline","title":"Chapter-5 Cognitive Planning Pipeline","description":"The Role of Planning in VLA Systems","source":"@site/docs/module-4-vla/chapter-5-cognitive-planning-pipeline.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-5-cognitive-planning-pipeline","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/chapter-5-cognitive-planning-pipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/Mehtab-kk/Physical-AI-Humanoid-Robotics-Book/edit/master/docs/module-4-vla/chapter-5-cognitive-planning-pipeline.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Chapter-5 Cognitive Planning Pipeline","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Chapter-4 Vision for VLA","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/chapter-4-vision-for-vla"},"next":{"title":"Chapter-6 Simulated Action Execution","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/chapter-6-simulated-action-execution"}}');var a=i(4848),s=i(8453);const t={title:"Chapter-5 Cognitive Planning Pipeline",sidebar_position:5},r="Cognitive Planning Pipeline",o={},c=[{value:"The Role of Planning in VLA Systems",id:"the-role-of-planning-in-vla-systems",level:2},{value:"Planning Hierarchy in VLA Systems",id:"planning-hierarchy-in-vla-systems",level:3},{value:"Planning Steps: Instruction \u2192 Perception \u2192 Robot Actions",id:"planning-steps-instruction--perception--robot-actions",level:2},{value:"1. Goal Interpretation",id:"1-goal-interpretation",level:3},{value:"2. Situation Assessment",id:"2-situation-assessment",level:3},{value:"3. Plan Generation",id:"3-plan-generation",level:3},{value:"4. Plan Validation",id:"4-plan-validation",level:3},{value:"5. Plan Execution",id:"5-plan-execution",level:3},{value:"LLM-Style Planning for Robot Task Generation",id:"llm-style-planning-for-robot-task-generation",level:2},{value:"Example: Setting a Table",id:"example-setting-a-table",level:3},{value:"Planning with Context Awareness",id:"planning-with-context-awareness",level:3},{value:"Creating Step-by-Step Robot Plans",id:"creating-step-by-step-robot-plans",level:2},{value:"Action Representation",id:"action-representation",level:3},{value:"Plan Sequencing",id:"plan-sequencing",level:3},{value:"Ensuring Safe and Predictable Actions",id:"ensuring-safe-and-predictable-actions",level:2},{value:"Safety Constraints Integration",id:"safety-constraints-integration",level:3},{value:"Plan Robustness",id:"plan-robustness",level:3},{value:"Validation Before Execution",id:"validation-before-execution",level:3},{value:"Planning Algorithms in VLA Systems",id:"planning-algorithms-in-vla-systems",level:2},{value:"Hierarchical Task Networks (HTN)",id:"hierarchical-task-networks-htn",level:3},{value:"Partial Order Planning",id:"partial-order-planning",level:3},{value:"Reactive Planning",id:"reactive-planning",level:3},{value:"Handling Uncertainty in Planning",id:"handling-uncertainty-in-planning",level:2},{value:"Perception Uncertainty",id:"perception-uncertainty",level:3},{value:"Action Uncertainty",id:"action-uncertainty",level:3},{value:"Planning Under Uncertainty",id:"planning-under-uncertainty",level:3},{value:"Simulation-Based Planning",id:"simulation-based-planning",level:2},{value:"Plan Simulation",id:"plan-simulation",level:3},{value:"What-If Analysis",id:"what-if-analysis",level:3},{value:"Practical Exercise: Creating a Cognitive Plan",id:"practical-exercise-creating-a-cognitive-plan",level:2},{value:"Exercise: Preparing a Simple Meal",id:"exercise-preparing-a-simple-meal",level:3},{value:"Looking Forward: Action Execution",id:"looking-forward-action-execution",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"cognitive-planning-pipeline",children:"Cognitive Planning Pipeline"})}),"\n",(0,a.jsx)(e.h2,{id:"the-role-of-planning-in-vla-systems",children:"The Role of Planning in VLA Systems"}),"\n",(0,a.jsx)(e.p,{children:'Cognitive planning serves as the "executive function" in VLA systems, taking high-level goals from language understanding and visual perception, then creating detailed sequences of actions that the robot can execute. This planning process must consider the robot\'s capabilities, environmental constraints, and safety requirements.'}),"\n",(0,a.jsx)(e.h3,{id:"planning-hierarchy-in-vla-systems",children:"Planning Hierarchy in VLA Systems"}),"\n",(0,a.jsx)(e.p,{children:"Planning occurs at multiple levels:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Task Planning"}),": High-level sequence of goals to achieve"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Motion Planning"}),": Detailed movement paths to execute actions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Action Planning"}),": Specific robot commands to carry out tasks"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Reactive Planning"}),": Real-time adjustments based on feedback"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"planning-steps-instruction--perception--robot-actions",children:"Planning Steps: Instruction \u2192 Perception \u2192 Robot Actions"}),"\n",(0,a.jsx)(e.p,{children:"The cognitive planning pipeline follows a structured flow:"}),"\n",(0,a.jsx)(e.h3,{id:"1-goal-interpretation",children:"1. Goal Interpretation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Receive high-level goal from language system"}),"\n",(0,a.jsx)(e.li,{children:"Identify constraints and preferences"}),"\n",(0,a.jsx)(e.li,{children:"Break down complex goals into subtasks"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"2-situation-assessment",children:"2. Situation Assessment"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Integrate current visual perception data"}),"\n",(0,a.jsx)(e.li,{children:"Identify relevant objects and obstacles"}),"\n",(0,a.jsx)(e.li,{children:"Assess environmental state"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"3-plan-generation",children:"3. Plan Generation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Create sequence of actions to achieve goals"}),"\n",(0,a.jsx)(e.li,{children:"Consider multiple possible approaches"}),"\n",(0,a.jsx)(e.li,{children:"Optimize for efficiency and safety"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"4-plan-validation",children:"4. Plan Validation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Check plan feasibility against robot capabilities"}),"\n",(0,a.jsx)(e.li,{children:"Verify safety constraints are met"}),"\n",(0,a.jsx)(e.li,{children:"Identify potential failure points"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"5-plan-execution",children:"5. Plan Execution"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Execute actions in sequence"}),"\n",(0,a.jsx)(e.li,{children:"Monitor progress and environment"}),"\n",(0,a.jsx)(e.li,{children:"Adapt plan as needed"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"llm-style-planning-for-robot-task-generation",children:"LLM-Style Planning for Robot Task Generation"}),"\n",(0,a.jsx)(e.p,{children:"Large Language Models can assist in creating structured robot plans by breaking down complex tasks:"}),"\n",(0,a.jsx)(e.h3,{id:"example-setting-a-table",children:"Example: Setting a Table"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:'Goal: "Set the table for dinner"\n\u2193\nLLM Decomposition:\n1. Task: Place plates\n   - Find plates (perception)\n   - Navigate to plates (motion planning)\n   - Grasp plates (manipulation planning)\n   - Navigate to table (motion planning)\n   - Place plates (manipulation planning)\n\n2. Task: Place utensils\n   - Find utensils (perception)\n   - Repeat similar sequence...\n\n3. Task: Place glasses\n   - Find glasses (perception)\n   - Repeat similar sequence...\n'})}),"\n",(0,a.jsx)(e.h3,{id:"planning-with-context-awareness",children:"Planning with Context Awareness"}),"\n",(0,a.jsx)(e.p,{children:"Effective planning considers:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Current state of the environment"}),"\n",(0,a.jsx)(e.li,{children:"Robot's current configuration"}),"\n",(0,a.jsx)(e.li,{children:"Available objects and their properties"}),"\n",(0,a.jsx)(e.li,{children:"Temporal and spatial constraints"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"creating-step-by-step-robot-plans",children:"Creating Step-by-Step Robot Plans"}),"\n",(0,a.jsx)(e.p,{children:"Robots require detailed, executable steps. The planning system must translate high-level goals into specific actions:"}),"\n",(0,a.jsx)(e.h3,{id:"action-representation",children:"Action Representation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:'{\n  "action_id": "step_001",\n  "action_type": "navigation",\n  "parameters": {\n    "target_pose": {"x": 1.2, "y": 0.5, "theta": 0.0},\n    "constraints": ["avoid_obstacles", "safe_speed"]\n  },\n  "success_criteria": "robot_reached_target",\n  "fallback_action": "replan_path"\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"plan-sequencing",children:"Plan Sequencing"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sequential Planning"}),": Actions in fixed order"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Conditional Planning"}),": Actions depend on outcomes"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Parallel Planning"}),": Multiple actions simultaneously possible"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"ensuring-safe-and-predictable-actions",children:"Ensuring Safe and Predictable Actions"}),"\n",(0,a.jsx)(e.p,{children:"Safety is paramount in cognitive planning:"}),"\n",(0,a.jsx)(e.h3,{id:"safety-constraints-integration",children:"Safety Constraints Integration"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Kinematic limits: Don't exceed joint ranges"}),"\n",(0,a.jsx)(e.li,{children:"Dynamic constraints: Respect acceleration limits"}),"\n",(0,a.jsx)(e.li,{children:"Collision avoidance: Prevent robot-object-human collisions"}),"\n",(0,a.jsx)(e.li,{children:"Operational limits: Stay within task boundaries"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"plan-robustness",children:"Plan Robustness"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Fallback Planning"}),": Alternative actions when primary plan fails"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Recovery Planning"}),": Return to safe state when errors occur"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Contingency Planning"}),": Pre-planned responses to common issues"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"validation-before-execution",children:"Validation Before Execution"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Kinematic feasibility checks"}),"\n",(0,a.jsx)(e.li,{children:"Dynamic constraint verification"}),"\n",(0,a.jsx)(e.li,{children:"Collision detection in planned path"}),"\n",(0,a.jsx)(e.li,{children:"Safety envelope compliance"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"planning-algorithms-in-vla-systems",children:"Planning Algorithms in VLA Systems"}),"\n",(0,a.jsx)(e.h3,{id:"hierarchical-task-networks-htn",children:"Hierarchical Task Networks (HTN)"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Decompose high-level tasks into primitive actions"}),"\n",(0,a.jsx)(e.li,{children:"Use domain knowledge to guide decomposition"}),"\n",(0,a.jsx)(e.li,{children:"Efficient for structured environments"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"partial-order-planning",children:"Partial Order Planning"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Allow flexibility in action ordering"}),"\n",(0,a.jsx)(e.li,{children:"Handle concurrent actions naturally"}),"\n",(0,a.jsx)(e.li,{children:"Adapt to changing conditions"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"reactive-planning",children:"Reactive Planning"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Respond to environmental changes in real-time"}),"\n",(0,a.jsx)(e.li,{children:"Adjust plans based on perception feedback"}),"\n",(0,a.jsx)(e.li,{children:"Maintain goal achievement despite disturbances"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"handling-uncertainty-in-planning",children:"Handling Uncertainty in Planning"}),"\n",(0,a.jsx)(e.p,{children:"Real environments contain uncertainty that planning systems must address:"}),"\n",(0,a.jsx)(e.h3,{id:"perception-uncertainty",children:"Perception Uncertainty"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Objects may not be precisely located"}),"\n",(0,a.jsx)(e.li,{children:"Sensor data may be noisy"}),"\n",(0,a.jsx)(e.li,{children:"Dynamic environments change over time"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"action-uncertainty",children:"Action Uncertainty"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Robot actions may not execute perfectly"}),"\n",(0,a.jsx)(e.li,{children:"Objects may move unexpectedly"}),"\n",(0,a.jsx)(e.li,{children:"Environmental conditions may change"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"planning-under-uncertainty",children:"Planning Under Uncertainty"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Probabilistic Planning"}),": Account for uncertainty in models"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Robust Planning"}),": Create plans that work under various conditions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptive Planning"}),": Modify plans as new information becomes available"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"simulation-based-planning",children:"Simulation-Based Planning"}),"\n",(0,a.jsx)(e.p,{children:"In our educational environment, planning is validated through simulation:"}),"\n",(0,a.jsx)(e.h3,{id:"plan-simulation",children:"Plan Simulation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Execute plans in virtual environment before real execution"}),"\n",(0,a.jsx)(e.li,{children:"Test for potential failures and safety issues"}),"\n",(0,a.jsx)(e.li,{children:"Optimize parameters and sequences"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"what-if-analysis",children:"What-If Analysis"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Test plan variations to find optimal approach"}),"\n",(0,a.jsx)(e.li,{children:"Analyze failure scenarios and develop contingencies"}),"\n",(0,a.jsx)(e.li,{children:"Evaluate plan efficiency and safety margins"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"practical-exercise-creating-a-cognitive-plan",children:"Practical Exercise: Creating a Cognitive Plan"}),"\n",(0,a.jsx)(e.p,{children:"Let's practice creating a cognitive plan for a complex task:"}),"\n",(0,a.jsx)(e.h3,{id:"exercise-preparing-a-simple-meal",children:"Exercise: Preparing a Simple Meal"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Goal"}),': "Make a peanut butter sandwich and pour a glass of juice"']}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Cognitive Plan"}),":"]}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Assessment Phase"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Identify ingredients: bread, peanut butter, knife, plate, juice, glass"}),"\n",(0,a.jsx)(e.li,{children:"Locate kitchen area with necessary items"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Planning Phase"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["Task 1: Prepare workspace","\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Navigate to counter"}),"\n",(0,a.jsx)(e.li,{children:"Clear space for food preparation"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["Task 2: Make sandwich","\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Grasp bread package"}),"\n",(0,a.jsx)(e.li,{children:"Extract two slices of bread"}),"\n",(0,a.jsx)(e.li,{children:"Place slices on plate"}),"\n",(0,a.jsx)(e.li,{children:"Grasp knife"}),"\n",(0,a.jsx)(e.li,{children:"Grasp peanut butter jar"}),"\n",(0,a.jsx)(e.li,{children:"Spread peanut butter on one slice"}),"\n",(0,a.jsx)(e.li,{children:"Combine slices"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["Task 3: Pour juice","\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Grasp glass"}),"\n",(0,a.jsx)(e.li,{children:"Navigate to refrigerator"}),"\n",(0,a.jsx)(e.li,{children:"Open refrigerator"}),"\n",(0,a.jsx)(e.li,{children:"Grasp juice container"}),"\n",(0,a.jsx)(e.li,{children:"Pour juice into glass"}),"\n",(0,a.jsx)(e.li,{children:"Close refrigerator"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Execution Phase"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Execute each sub-task sequentially"}),"\n",(0,a.jsx)(e.li,{children:"Monitor progress and environment"}),"\n",(0,a.jsx)(e.li,{children:"Adjust plan as needed"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"looking-forward-action-execution",children:"Looking Forward: Action Execution"}),"\n",(0,a.jsx)(e.p,{children:"The next chapter explores how these cognitive plans are translated into actual robot actions in the simulation environment."}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Previous"}),": ",(0,a.jsx)(e.a,{href:"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/chapter-4-vision-for-vla",children:"Chapter 4: Vision for VLA"}),"\n",(0,a.jsx)(e.strong,{children:"Next"}),": ",(0,a.jsx)(e.a,{href:"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/chapter-6-simulated-action-execution",children:"Chapter 6: Simulated Action Execution"})]})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>t,x:()=>r});var l=i(6540);const a={},s=l.createContext(a);function t(n){const e=l.useContext(s);return l.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:t(n.components),l.createElement(s.Provider,{value:e},n.children)}}}]);