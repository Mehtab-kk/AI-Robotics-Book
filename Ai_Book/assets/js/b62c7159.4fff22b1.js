"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[168],{2713:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-3-ai-robot-brain/chapter-08-mini-project","title":"chapter-8 Mini-Project: AI-Robot Brain Test","description":"Overview","source":"@site/docs/module-3-ai-robot-brain/chapter-08-mini-project.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/chapter-08-mini-project","permalink":"/AI-Robotics-Book/docs/module-3-ai-robot-brain/chapter-08-mini-project","draft":false,"unlisted":false,"editUrl":"https://github.com/Mehtab-kk/AI-Robotics-Book/edit/main/docs/module-3-ai-robot-brain/chapter-08-mini-project.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"chapter-08-mini-project","title":"chapter-8 Mini-Project: AI-Robot Brain Test","sidebar_position":8},"sidebar":"tutorialSidebar","previous":{"title":"chapter-7 AI Action Planning","permalink":"/AI-Robotics-Book/docs/module-3-ai-robot-brain/chapter-07-ai-action-planning"},"next":{"title":"Chapter-1 Introduction to Vision-Language-Action Systems","permalink":"/AI-Robotics-Book/docs/module-4-vla/chapter-1-introduction-to-vla"}}');var a=i(4848),r=i(8453);const o={id:"chapter-08-mini-project",title:"chapter-8 Mini-Project: AI-Robot Brain Test",sidebar_position:8},s="Mini-Project: AI-Robot Brain Test",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Project Objective",id:"project-objective",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Implementation Steps",id:"implementation-steps",level:2},{value:"Step 1: Environment Setup",id:"step-1-environment-setup",level:3},{value:"Step 2: Sensor Integration System",id:"step-2-sensor-integration-system",level:3},{value:"Step 3: VSLAM Integration",id:"step-3-vslam-integration",level:3},{value:"Step 4: Nav2 Path Planning",id:"step-4-nav2-path-planning",level:3},{value:"Step 5: AI Action Planning",id:"step-5-ai-action-planning",level:3},{value:"Step 6: Complete Integration Loop",id:"step-6-complete-integration-loop",level:3},{value:"Testing Scenarios",id:"testing-scenarios",level:2},{value:"Scenario 1: Simple Navigation",id:"scenario-1-simple-navigation",level:3},{value:"Scenario 2: Obstacle Avoidance",id:"scenario-2-obstacle-avoidance",level:3},{value:"Scenario 3: Dynamic Environment",id:"scenario-3-dynamic-environment",level:3},{value:"Scenario 4: Complex Navigation",id:"scenario-4-complex-navigation",level:3},{value:"Assessment Criteria",id:"assessment-criteria",level:2},{value:"Performance Metrics",id:"performance-metrics",level:3},{value:"System Integration",id:"system-integration",level:3},{value:"AI Decision Quality",id:"ai-decision-quality",level:3},{value:"Mini-Exercise",id:"mini-exercise",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"mini-project-ai-robot-brain-test",children:"Mini-Project: AI-Robot Brain Test"})}),"\n",(0,a.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(e.p,{children:"In this final chapter, we'll integrate all the concepts from Module 3 to create a complete AI-robot brain system. This mini-project combines Isaac Sim, Isaac ROS, VSLAM, Nav2, sensor integration, and AI action planning into a unified system for a humanoid robot."}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"AI-Robot Brain (AI Robot ka dimag):"})," The integrated system that combines perception, planning, and action for intelligent robot behavior."]}),"\n",(0,a.jsx)(e.h2,{id:"project-objective",children:"Project Objective"}),"\n",(0,a.jsx)(e.p,{children:"Create an AI-powered humanoid robot that can:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Navigate autonomously in a simulated environment"}),"\n",(0,a.jsx)(e.li,{children:"Use VSLAM for localization and mapping"}),"\n",(0,a.jsx)(e.li,{children:"Plan paths using Nav2 to reach specified goals"}),"\n",(0,a.jsx)(e.li,{children:"Integrate multiple sensors for perception"}),"\n",(0,a.jsx)(e.li,{children:"Make intelligent decisions using AI action planning"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,a.jsx)(e.p,{children:"The complete AI-robot brain system architecture:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"Isaac Sim (Environment)\r\n    \u2193\r\nIsaac ROS (Communication Framework)\r\n    \u2193\r\nSensor Integration (Perception)\r\n    \u2193\r\nVSLAM (Localization & Mapping)\r\n    \u2193\r\nAI Action Planner (Decision Making)\r\n    \u2193\r\nNav2 (Path Planning & Execution)\r\n    \u2193\r\nRobot Control (Physical Actions)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,a.jsx)(e.h3,{id:"step-1-environment-setup",children:"Step 1: Environment Setup"}),"\n",(0,a.jsx)(e.p,{children:"Configure Isaac Sim with a realistic indoor environment:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Environment configuration\r\nenvironment_config = {\r\n    "scene": "office_building",\r\n    "lighting": "realistic",\r\n    "objects": ["desks", "chairs", "people", "obstacles"],\r\n    "sensors": ["rgb_camera", "lidar", "imu", "depth_camera"]\r\n}\r\n\r\n# Create simulation environment\r\nsim_env = IsaacSimulationEnvironment()\r\nsim_env.create_scene(environment_config)\n'})}),"\n",(0,a.jsx)(e.h3,{id:"step-2-sensor-integration-system",children:"Step 2: Sensor Integration System"}),"\n",(0,a.jsx)(e.p,{children:"Implement the sensor fusion system:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# Initialize sensor integration\r\nsensor_system = SensorIntegration()\r\nsensor_system.sensor_fusion_enabled = True\r\nsensor_system.sensor_types = ['rgb_camera', 'lidar', 'imu', 'depth_camera']\r\nsensor_system.data_frequency = 20  # Hz\r\n\r\ndef process_sensor_data():\r\n    # Collect data from all sensors\r\n    camera_data = get_camera_data()\r\n    lidar_data = get_lidar_data()\r\n    imu_data = get_imu_data()\r\n    depth_data = get_depth_data()\r\n\r\n    # Fuse sensor data\r\n    fused_perception = sensor_system.integrate_sensors([\r\n        camera_data, lidar_data, imu_data, depth_data\r\n    ])\r\n\r\n    return fused_perception\n"})}),"\n",(0,a.jsx)(e.h3,{id:"step-3-vslam-integration",children:"Step 3: VSLAM Integration"}),"\n",(0,a.jsx)(e.p,{children:"Connect the VSLAM system for localization:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# Initialize VSLAM system\r\nvslam_system = VSLAMSystem()\r\nvslam_system.algorithm_type = \"ORB_SLAM\"\r\nvslam_system.map_resolution = 0.05\r\nvslam_system.localization_accuracy = 0.02\r\n\r\ndef update_localization(image_frame):\r\n    # Process frame through VSLAM\r\n    vslam_result = vslam_system.process_frame(image_frame)\r\n\r\n    # Update robot pose estimate\r\n    robot_pose = vslam_result['pose']\r\n\r\n    # Update map\r\n    map_update = vslam_result['map']\r\n\r\n    return robot_pose, map_update\n"})}),"\n",(0,a.jsx)(e.h3,{id:"step-4-nav2-path-planning",children:"Step 4: Nav2 Path Planning"}),"\n",(0,a.jsx)(e.p,{children:"Configure Nav2 for humanoid robot navigation:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Initialize Nav2 planner\r\nnav2_planner = Nav2PathPlanner()\r\nnav2_planner.robot_type = "humanoid"\r\nnav2_planner.costmap_resolution = 0.05\r\nnav2_planner.inflation_radius = 0.6\r\n\r\ndef plan_and_execute_navigation(goal_pose):\r\n    # Get current robot pose from VSLAM\r\n    current_pose = get_current_pose()\r\n\r\n    # Compute path to goal\r\n    path = nav2_planner.compute_path(current_pose, goal_pose)\r\n\r\n    # Execute path following\r\n    execution_result = nav2_planner.execute_path(path, controller_config)\r\n\r\n    return execution_result\n'})}),"\n",(0,a.jsx)(e.h3,{id:"step-5-ai-action-planning",children:"Step 5: AI Action Planning"}),"\n",(0,a.jsx)(e.p,{children:"Implement the AI decision-making system:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Initialize AI action planner\r\nai_planner = AIActionPlanner()\r\nai_planner.decision_algorithm = "hybrid"\r\nai_planner.planning_horizon = 3.0\r\nai_planner.safety_constraints = ["avoid_collisions", "maintain_balance"]\r\n\r\ndef make_intelligent_decisions(perception_data):\r\n    # Plan action based on perception\r\n    action_plan = ai_planner.plan_action(perception_data)\r\n\r\n    # Evaluate plan safety\r\n    evaluation = ai_planner.evaluate_plan(action_plan)\r\n\r\n    if evaluation.is_safe:\r\n        # Execute decision\r\n        return ai_planner.execute_decision(action_plan.decision)\r\n    else:\r\n        # Execute safe fallback\r\n        return ai_planner.execute_decision("safe_behavior")\n'})}),"\n",(0,a.jsx)(e.h3,{id:"step-6-complete-integration-loop",children:"Step 6: Complete Integration Loop"}),"\n",(0,a.jsx)(e.p,{children:"Combine all systems into a cohesive loop:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def ai_robot_brain_main_loop():\r\n    """\r\n    Main loop for the AI-robot brain system\r\n    Integrates all components in a coordinated manner\r\n    """\r\n    while not goal_reached():\r\n        # 1. Collect sensor data\r\n        perception_data = process_sensor_data()\r\n\r\n        # 2. Update localization using VSLAM\r\n        robot_pose, map_update = update_localization(perception_data[\'camera\'])\r\n\r\n        # 3. Update Nav2 costmap with new information\r\n        nav2_planner.update_costmap(perception_data[\'sensors\'])\r\n\r\n        # 4. Make intelligent decisions\r\n        decision = make_intelligent_decisions(perception_data)\r\n\r\n        # 5. Plan and execute navigation if needed\r\n        if decision.requires_navigation:\r\n            navigation_result = plan_and_execute_navigation(decision.goal_pose)\r\n\r\n        # 6. Update system state and continue\r\n        update_system_state()\r\n\r\n        # 7. Sleep for appropriate time\r\n        time.sleep(1.0 / control_frequency)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"testing-scenarios",children:"Testing Scenarios"}),"\n",(0,a.jsx)(e.p,{children:"Test the complete system with various scenarios:"}),"\n",(0,a.jsx)(e.h3,{id:"scenario-1-simple-navigation",children:"Scenario 1: Simple Navigation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Robot navigates from start to goal in an empty room"}),"\n",(0,a.jsx)(e.li,{children:"Verify basic path planning and execution"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"scenario-2-obstacle-avoidance",children:"Scenario 2: Obstacle Avoidance"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Robot encounters static obstacles in its path"}),"\n",(0,a.jsx)(e.li,{children:"Verify dynamic path replanning and obstacle avoidance"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"scenario-3-dynamic-environment",children:"Scenario 3: Dynamic Environment"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Moving obstacles (simulated people) in the environment"}),"\n",(0,a.jsx)(e.li,{children:"Verify real-time adaptation to changing conditions"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"scenario-4-complex-navigation",children:"Scenario 4: Complex Navigation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Multi-room navigation with doorways"}),"\n",(0,a.jsx)(e.li,{children:"Verify map building and localization in complex environments"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"assessment-criteria",children:"Assessment Criteria"}),"\n",(0,a.jsx)(e.p,{children:"Evaluate the AI-robot brain system based on:"}),"\n",(0,a.jsx)(e.h3,{id:"performance-metrics",children:"Performance Metrics"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Navigation Success Rate"}),": Percentage of successful goal reaches"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Path Efficiency"}),": Ratio of actual path length to optimal path"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Collision Avoidance"}),": Number of collisions during navigation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Localization Accuracy"}),": Error in robot position estimation"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"system-integration",children:"System Integration"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Component Coordination"}),": How well different systems work together"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Real-time Performance"}),": Ability to maintain required update rates"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Robustness"}),": System behavior under various conditions"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"ai-decision-quality",children:"AI Decision Quality"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Intelligent Behavior"}),": Appropriate responses to different situations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Safety Compliance"}),": Adherence to safety constraints"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Goal Achievement"}),": Success in accomplishing assigned tasks"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"mini-exercise",children:"Mini-Exercise"}),"\n",(0,a.jsx)(e.p,{children:"Extend the AI-robot brain system to include a simple task where the robot must find and approach a specific object in the environment. What additional components would you need to add to the system?"}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"This mini-project demonstrates the integration of all concepts from Module 3: Isaac Sim for realistic simulation, Isaac ROS for communication, VSLAM for mapping, Nav2 for navigation, sensor integration for perception, and AI action planning for intelligent decision-making. The AI-robot brain system represents a complete approach to autonomous robot intelligence."}),"\n",(0,a.jsx)(e.p,{children:"Congratulations on completing Module 3! You now understand how to create intelligent, autonomous humanoid robots using the NVIDIA Isaac ecosystem."})]})}function p(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);